"""
–°—Ç—Ä–∏–º–∏–Ω–≥–æ–≤—ã–π —Å–µ—Ä–≤–µ—Ä –¥–ª—è BOOOMERANGS
–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –ø–æ—Ç–æ–∫–æ–≤—É—é –ø–µ—Ä–µ–¥–∞—á—É –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç –º–æ–¥–µ–ª–µ–π G4F
"""
from flask import Flask, request, Response, jsonify
from flask_cors import CORS
import g4f
import json
import time
import random
import traceback

# –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø–æ—Ç–æ–∫–æ–≤–æ–π –ø–µ—Ä–µ–¥–∞—á–∏
# –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –≥–∏–±–∫–∏–π –ø–æ–¥—Ö–æ–¥ —Å getattr –≤–º–µ—Å—Ç–æ –ø—Ä—è–º–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
# –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –æ—à–∏–±–æ–∫ AttributeError
def get_provider(name):
    try:
        return getattr(g4f.Provider, name)
    except AttributeError:
        print(f"–ü—Ä–æ–≤–∞–π–¥–µ—Ä {name} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ g4f")
        return None

providers = {}
# –î–æ–±–∞–≤–ª—è–µ–º Llama 3 –≤ —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
for name in ["Qwen_Qwen_2_5_Max", "Qwen_Qwen_3", "You", "DeepInfra", "Gemini", "GeminiPro", "Phind", "Liaobots", "Anthropic", "Ollama", "HuggingChat"]:
    provider = get_provider(name)
    if provider:
        providers[name] = provider
        print(f"–£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –ø—Ä–æ–≤–∞–π–¥–µ—Ä: {name}")
    else:
        print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ–≤–∞–π–¥–µ—Ä: {name}")

# –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã Llama –∏ –¥—Ä—É–≥–∏–µ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏
llama_providers = []
gpt_providers = []  # –î–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ GPT
all_provider_names = []
try:
    all_provider_names = [name for name in dir(g4f.Provider) if not name.startswith('_')]
    print(f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤: {len(all_provider_names)}")
except Exception as e:
    print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤: {str(e)}")
    all_provider_names = []

# –ò—â–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã —Å llama –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
for name in all_provider_names:
    if "llama" in name.lower():
        print(f"–ù–∞–π–¥–µ–Ω –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π Llama –ø—Ä–æ–≤–∞–π–¥–µ—Ä: {name}")
        provider = get_provider(name)
        if provider:
            providers[name] = provider
            llama_providers.append(name)
            print(f"ü¶ô –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω Llama –ø—Ä–æ–≤–∞–π–¥–µ—Ä: {name}")
            
# –ò—â–µ–º GPT –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ
gpt_potential_providers = [
    "DeepAI", "AiChats", "Poe", "AIChatOnline", "GigaChat", "GPTalk", 
    "ChatGpt", "Chatgpt4Online", "OpenaiChat", "GPROChat", "FreeChatgpt", 
    "You", "MyShell", "FreeGpt", "Gemini", "Bing", "OpenaiAPI",
    "DeepInfra", "GptGo"
]

for name in gpt_potential_providers:
    if name not in providers and name in all_provider_names:
        provider = get_provider(name)
        if provider:
            providers[name] = provider
            gpt_providers.append(name)
            print(f"üî• –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π GPT –ø—Ä–æ–≤–∞–π–¥–µ—Ä: {name}")
            
# –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å GPT-3.5
priority_gpt_providers = ["DeepInfra", "You", "Gemini", "ChatGpt"]
for name in priority_gpt_providers:
    if name in providers:
        # –ü—Ä–æ–±—É–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ª–∏ –¥–∞–Ω–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä GPT-3.5 Turbo
        print(f"‚ö° –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ GPT-3.5 Turbo —É –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ {name}...")
        
# –ò—â–µ–º Llama 3 —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ
for name in ["HuggingFace", "HuggingSpace", "HuggingChat", "Ollama", "Replicate"]:
    if name not in providers and name in all_provider_names:
        provider = get_provider(name)
        if provider:
            providers[name] = provider
            print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è –º–æ–¥–µ–ª–µ–π Llama: {name}")
            
# –î–æ–±–∞–≤–ª—è–µ–º –≤ —Å–ø–∏—Å–æ–∫ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ —Å Llama
if "HuggingChat" in providers:
    llama_providers.append("HuggingChat")
if "Ollama" in providers:
    llama_providers.append("Ollama")

# –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Claude —á–µ—Ä–µ–∑ Anthropic
anthropic_available = "Anthropic" in providers
llama_available = len(llama_providers) > 0

if llama_available:
    print(f"‚úÖ –ü—Ä–æ–≤–∞–π–¥–µ—Ä—ã Llama –¥–æ—Å—Ç—É–ø–Ω—ã: {', '.join(llama_providers)}")
else:
    print("‚ùå –ü—Ä–æ–≤–∞–π–¥–µ—Ä—ã Llama –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
if anthropic_available:
    print("‚úÖ –ü—Ä–æ–≤–∞–π–¥–µ—Ä Anthropic (Claude) –¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è!")
else:
    print("‚ùå –ü—Ä–æ–≤–∞–π–¥–µ—Ä Anthropic (Claude) –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –∏–ª–∏ —Ç—Ä–µ–±—É–µ—Ç API –∫–ª—é—á")

# –û—Ä–≥–∞–Ω–∏–∑—É–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –≤ –≥—Ä—É–ø–ø—ã –ø–æ –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏
provider_groups = {
    'primary': ['Qwen_Qwen_2_5_Max', 'Qwen_Qwen_3', 'You', 'DeepInfra'],
    'secondary': ['Gemini', 'GeminiPro', 'Phind', 'ChatGpt'],
    'fallback': ['You', 'DeepInfra', 'GPTalk', 'FreeGpt', 'GptGo']
}

# –î–æ–±–∞–≤–ª—è–µ–º –≥—Ä—É–ø–ø—É –¥–ª—è GPT-3.5
gpt_providers_group = ['DeepInfra', 'You', 'ChatGpt', 'GPTalk', 'FreeGpt', 'GptGo']

# –î–æ–±–∞–≤–ª—è–µ–º Claude –≤ –≥—Ä—É–ø–ø—ã, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
if anthropic_available:
    provider_groups['primary'].insert(0, 'Anthropic')  # –î–æ–±–∞–≤–ª—è–µ–º –≤ –Ω–∞—á–∞–ª–æ —Å–ø–∏—Å–∫–∞ primary
    
# –î–æ–±–∞–≤–ª—è–µ–º Llama –≤ –≥—Ä—É–ø–ø—ã, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
if llama_available:
    for llama_provider in llama_providers:
        # –î–æ–±–∞–≤–ª—è–µ–º Llama –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –≤ –Ω–∞—á–∞–ª–æ primary –≥—Ä—É–ø–ø—ã
        provider_groups['primary'].insert(0, llama_provider)
        print(f"ü¶ô –î–æ–±–∞–≤–ª–µ–Ω Llama –ø—Ä–æ–≤–∞–π–¥–µ—Ä {llama_provider} –≤ primary –≥—Ä—É–ø–ø—É")

app = Flask(__name__)
CORS(app)

@app.route('/python/ai', methods=['POST'])
def python_ai_chat():
    """–û—Å–Ω–æ–≤–Ω–æ–π —ç–Ω–¥–ø–æ–π–Ω—Ç –¥–ª—è –æ–±—â–µ–Ω–∏—è —Å AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏"""
    try:
        data = request.get_json()
        message = data.get('message', '')
        provider_name = data.get('provider', 'auto')
        
        if not message:
            return jsonify({"error": "–°–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ —É–∫–∞–∑–∞–Ω–æ"}), 400
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
        if provider_name == 'auto':
            provider_name = random.choice(list(providers.keys()))
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä
        if provider_name not in providers:
            return jsonify({"error": f"–ü—Ä–æ–≤–∞–π–¥–µ—Ä {provider_name} –Ω–µ –Ω–∞–π–¥–µ–Ω"}), 400
        
        provider = providers[provider_name]
        
        # –°–æ–∑–¥–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –¥–∏–∞–ª–æ–≥–∞
        messages = [
            {"role": "system", "content": "–í—ã AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç BOOOMERANGS. –û—Ç–≤–µ—á–∞–π—Ç–µ –ø–æ-—Ä—É—Å—Å–∫–∏, –µ—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–∞ —Ä—É—Å—Å–∫–æ–º. –î–∞–≤–∞–π—Ç–µ –∫—Ä–∞—Ç–∫–∏–µ –∏ –ø–æ–ª–µ–∑–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã."},
            {"role": "user", "content": message}
        ]
        
        print(f"ü§ñ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ {provider_name}: {message[:50]}...")
        
        # –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
        model = "gpt-4o-mini"  # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
        if provider_name == "You":
            model = "gpt-4o"
        elif provider_name == "Anthropic":
            model = "claude-3.5-sonnet"
        elif provider_name == "Gemini":
            model = "gemini-1-5-flash"
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—É
        response = g4f.ChatCompletion.create(
            model=model,
            messages=messages,
            provider=provider,
            timeout=30
        )
        
        return jsonify({
            "success": True,
            "response": response,
            "provider": provider_name,
            "model": "gpt-3.5-turbo"
        })
        
    except Exception as e:
        error_msg = str(e)
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤ python_ai_chat: {error_msg}")
        
        return jsonify({
            "success": False,
            "error": error_msg,
            "provider": provider_name if 'provider_name' in locals() else 'unknown'
        }), 500

# –§–£–ù–ö–¶–ò–Ø get_demo_response –ü–û–õ–ù–û–°–¢–¨–Æ –£–î–ê–õ–ï–ù–ê - –±–æ–ª—å—à–µ –Ω–∏–∫–∞–∫–∏—Ö –∑–∞–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤!

@app.route('/stream', methods=['POST'])
def stream_chat():
    """–ü–æ—Ç–æ–∫–æ–≤—ã–π –≤—ã–≤–æ–¥ –æ—Ç–≤–µ—Ç–æ–≤ –æ—Ç G4F –º–æ–¥–µ–ª–µ–π —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Å—Ç—Ä–∏–º–∏–Ω–≥–∞"""
    if request.method != 'POST':
        return Response('–ú–µ—Ç–æ–¥ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è', status=405)
    
    try:
        data = request.get_json()
        message = data.get('message', '')
        provider_name = data.get('provider', 'Qwen_Qwen_2_5_Max')
        timeout = data.get('timeout', 20000) / 1000  # –ü–µ—Ä–µ–≤–æ–¥–∏–º –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã –≤ —Å–µ–∫—É–Ω–¥—ã
        
        if not message:
            return Response('–ù–µ —É–∫–∞–∑–∞–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ', status=400)
            
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö –∫–æ–º–∞–Ω–¥ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
        if message.lower().startswith('test-claude:'):
            message = message[11:].strip()  # –£–¥–∞–ª—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å
            provider_name = 'Anthropic'
            print(f"üîµ –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å: —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ Claude —Å —Å–æ–æ–±—â–µ–Ω–∏–µ–º: '{message}'")
        elif message.lower().startswith('test-provider:'):
            parts = message[13:].strip().split(':', 1)
            if len(parts) == 2:
                provider_name = parts[0].strip()
                message = parts[1].strip()
                print(f"üîµ –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å: —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ {provider_name} —Å —Å–æ–æ–±—â–µ–Ω–∏–µ–º: '{message}'")
        
        print(f"–ü–æ–ª—É—á–µ–Ω –∑–∞–ø—Ä–æ—Å —Å—Ç—Ä–∏–º–∏–Ω–≥–∞: '{message}' –æ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ {provider_name}")
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∏–∞–ª–æ–≥ —Å —Å–∏—Å—Ç–µ–º–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º
        messages = [
            {"role": "system", "content": "–í—ã AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç BOOOMERANGS. –û—Ç–≤–µ—á–∞–π—Ç–µ –ø–æ-—Ä—É—Å—Å–∫–∏, –µ—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–∞ —Ä—É—Å—Å–∫–æ–º. –î–∞–≤–∞–π—Ç–µ –∫—Ä–∞—Ç–∫–∏–µ –∏ –ø–æ–ª–µ–∑–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã."},
            {"role": "user", "content": message}
        ]
        
        def stream_generator():
            """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–ª—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–æ–≤"""
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –≤–Ω—É—Ç—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
            current_provider = provider_name
            start_time = time.time()
            yielded_anything = False
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–±—ã—Ç–∏–µ –Ω–∞—á–∞–ª–∞ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞
            print(f"–ù–∞—á–∏–Ω–∞–µ–º —Å—Ç—Ä–∏–º–∏–Ω–≥ –æ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ {current_provider}")
            yield f"event: start\ndata: {json.dumps({'provider': current_provider})}\n\n"
            
            try:
                # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –∏–º—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                if current_provider == "Qwen_Max":
                    current_provider = "Qwen_Qwen_2_5_Max"
                
                # –ü–æ–ø—Ä–æ–±—É–µ–º —Å–Ω–∞—á–∞–ª–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—à–µ–Ω–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä
                if current_provider in providers:
                    try:
                        provider = providers[current_provider]
                        print(f"–ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ {current_provider}")
                        
                        # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
                        try:
                            print(f"üîç –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è {current_provider}")
                            model = "gpt-3.5-turbo"
                            
                            # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
                            if current_provider == "Anthropic":
                                print(f"‚≠ê –ó–∞–ø—Ä–æ—Å –∫ Claude —á–µ—Ä–µ–∑ –ø—Ä–æ–≤–∞–π–¥–µ—Ä Anthropic")
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ç—Ä–µ–±—É–µ—Ç—Å—è –ª–∏ API-–∫–ª—é—á
                                try:
                                    # –ü–æ–ø—ã—Ç–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–µ–∑ –∫–ª—é—á–∞ - —ç—Ç–æ –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç—Ä–µ–±—É–µ—Ç—Å—è –ª–∏ –∫–ª—é—á –≤–æ–æ–±—â–µ
                                    response_stream = g4f.ChatCompletion.create(
                                        model="claude-3-opus-20240229",
                                        messages=messages,
                                        provider=provider,
                                        stream=True,
                                        timeout=timeout
                                    )
                                    print("‚úÖ Provider Anthropic –Ω–µ —Ç—Ä–µ–±—É–µ—Ç API –∫–ª—é—á–∞!")
                                except Exception as claude_error:
                                    error_str = str(claude_error)
                                    print(f"‚ùå –û—à–∏–±–∫–∞ Claude: {error_str}")
                                    if "api_key" in error_str.lower() or "apikey" in error_str.lower() or "key" in error_str.lower() or "token" in error_str.lower():
                                        print("‚ö†Ô∏è Claude —Ç—Ä–µ–±—É–µ—Ç –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–π API-–∫–ª—é—á")
                                        # –í–æ–∑–±—É–∂–¥–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ, —á—Ç–æ–±—ã –ø–µ—Ä–µ–π—Ç–∏ –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –ø—Ä–æ–≤–∞–π–¥–µ—Ä—É
                                        raise Exception("Claude —Ç—Ä–µ–±—É–µ—Ç API-–∫–ª—é—á")
                                    else:
                                        print("‚ö†Ô∏è –î—Ä—É–≥–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ Claude")
                                        raise
                            elif current_provider == "You":
                                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è - –µ—Å–ª–∏ –æ–Ω –ø—Ä–æ—Å–∏—Ç GPT-3.5, –º—ã –ø–æ–ø—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–≥–æ
                                if "gpt" in message.lower() or "test-gpt" in message.lower():
                                    print(f"‚≠ê –ó–∞–ø—Ä–æ—Å –∫ You.com —Å –º–æ–¥–µ–ª—å—é GPT")
                                    # –£–¥–∞–ª—è–µ–º –ø—Ä–µ—Ñ–∏–∫—Å test-gpt: –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç
                                    if message.lower().startswith("test-gpt:"):
                                        original_message = message
                                        message = message[9:].strip()
                                        # –û–±–Ω–æ–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –¥–∏–∞–ª–æ–≥–µ
                                        for m in messages:
                                            if m['role'] == 'user' and m['content'] == original_message:
                                                m['content'] = message
                                        print(f"üîÑ –û–±–Ω–æ–≤–∏–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞: {message}")
                                    try:
                                        model_to_use = "gpt-4o-mini"  # You –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç GPT-4o mini
                                        print(f"üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å {model_to_use} –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ You")
                                        response_stream = g4f.ChatCompletion.create(
                                            model=model_to_use,
                                            messages=messages,
                                            provider=provider,
                                            stream=True,
                                            timeout=timeout
                                        )
                                        print("‚úÖ Provider You —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–∏–ª –∑–∞–ø—Ä–æ—Å –∫ GPT!")
                                    except Exception as gpt_error:
                                        error_str = str(gpt_error)
                                        print(f"‚ùå –û—à–∏–±–∫–∞ You —Å –º–æ–¥–µ–ª—å—é GPT: {error_str}")
                                        
                                        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥—É—é GPT –º–æ–¥–µ–ª—å
                                        try:
                                            fallback_model = "gpt-4-turbo"
                                            print(f"üîÑ –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥—É—é GPT –º–æ–¥–µ–ª—å {fallback_model}")
                                            response_stream = g4f.ChatCompletion.create(
                                                model=fallback_model,
                                                messages=messages,
                                                provider=provider,
                                                stream=True,
                                                timeout=timeout
                                            )
                                            print(f"‚úÖ Provider You —É—Å–ø–µ—à–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª –º–æ–¥–µ–ª—å {fallback_model}!")
                                        except Exception:
                                            # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å GPT, –ø—Ä–æ–±—É–µ–º Llama
                                            try:
                                                llama_model = "llama-3"
                                                print(f"üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ Llama –º–æ–¥–µ–ª—å {llama_model}")
                                                response_stream = g4f.ChatCompletion.create(
                                                    model=llama_model,
                                                    messages=messages,
                                                    provider=provider,
                                                    stream=True,
                                                    timeout=timeout
                                                )
                                                print(f"‚úÖ Provider You —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–∫–ª—é—á–∏–ª—Å—è –Ω–∞ {llama_model}!")
                                            except Exception as fallback_error:
                                                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ Llama: {str(fallback_error)}")
                                                raise
                                else:
                                    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ Llama 3
                                    print(f"‚≠ê –ó–∞–ø—Ä–æ—Å –∫ You.com (—Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Llama 3)")
                                    try:
                                        model_to_use = "llama-3"  # –ò—Å–ø–æ–ª—å–∑—É–µ–º llama-3 –≤–º–µ—Å—Ç–æ gpt-3.5-turbo
                                        print(f"üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å {model_to_use} –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ You")
                                        response_stream = g4f.ChatCompletion.create(
                                            model=model_to_use,
                                            messages=messages,
                                            provider=provider,
                                            stream=True,
                                            timeout=timeout
                                        )
                                        print("‚úÖ Provider You —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–∏–ª –∑–∞–ø—Ä–æ—Å –∫ Llama 3!")
                                    except Exception as you_error:
                                        error_str = str(you_error)
                                        print(f"‚ùå –û—à–∏–±–∫–∞ You —Å –º–æ–¥–µ–ª—å—é llama-3: {error_str}")
                                        # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å
                                        try:
                                            fallback_model = "claude-3-haiku"  # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å
                                            print(f"üîÑ –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—É—é –º–æ–¥–µ–ª—å {fallback_model}")
                                            response_stream = g4f.ChatCompletion.create(
                                                model=fallback_model,
                                                messages=messages,
                                                provider=provider,
                                                stream=True,
                                                timeout=timeout
                                            )
                                            print(f"‚úÖ Provider You —É—Å–ø–µ—à–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª –º–æ–¥–µ–ª—å {fallback_model}!")
                                        except Exception as fallback_error:
                                            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –º–æ–¥–µ–ª–∏: {str(fallback_error)}")
                                            raise
                            elif current_provider in gpt_providers_group:
                                # –ü—Ä–æ–≤–∞–π–¥–µ—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Å GPT
                                print(f"‚≠ê –ó–∞–ø—Ä–æ—Å –∫ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—É {current_provider} —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π GPT")
                                try:
                                    # –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
                                    gpt_model_to_use = "gpt-3.5-turbo"
                                    if current_provider == "ChatGpt":
                                        gpt_model_to_use = "gpt-3.5-turbo"
                                    elif current_provider == "GPTalk":
                                        gpt_model_to_use = "gpt-3.5-turbo"
                                    elif current_provider == "You":
                                        # You –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –±–æ–ª–µ–µ –Ω–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ GPT
                                        gpt_model_to_use = "gpt-4o-mini"
                                    
                                    print(f"üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å {gpt_model_to_use} –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ {current_provider}")
                                    response_stream = g4f.ChatCompletion.create(
                                        model=gpt_model_to_use,
                                        messages=messages,
                                        provider=provider,
                                        stream=True,
                                        timeout=timeout
                                    )
                                    print(f"‚úÖ Provider {current_provider} —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–∏–ª –∑–∞–ø—Ä–æ—Å!")
                                except Exception as gpt_error:
                                    error_str = str(gpt_error)
                                    print(f"‚ùå –û—à–∏–±–∫–∞ {current_provider}: {error_str}")
                                    raise
                            else:
                                # –î–ª—è –≤—Å–µ—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –∑–∞–ø—Ä–æ—Å
                                # —Å –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫–æ–π –º–æ–¥–µ–ª–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
                                model_to_use = model
                                if current_provider in ["Qwen_Qwen_2_5_Max", "Qwen_Qwen_3"]:
                                    model_to_use = model  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è Qwen
                                
                                response_stream = g4f.ChatCompletion.create(
                                    model=model_to_use,
                                    messages=messages,
                                    provider=provider,
                                    stream=True,
                                    timeout=timeout
                                )
                            
                            print(f"–ü–æ–ª—É—á–µ–Ω –ø–æ—Ç–æ–∫ –æ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ {current_provider}")
                            response_text = ''
                            chunk_count = 0
                            
                            # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å –ø–µ—Ä–≤—ã–π —á–∞–Ω–∫ —Å —Ç–∞–π–º–∞—É—Ç–æ–º
                            got_first_chunk = False
                            
                            for chunk in response_stream:
                                chunk_count += 1
                                if isinstance(chunk, str):
                                    response_text += chunk
                                    print(f"–ß–∞–Ω–∫ {chunk_count} –æ—Ç {current_provider}: {chunk[:30]}...")
                                    yield f"event: chunk\ndata: {json.dumps({'text': chunk, 'provider': current_provider})}\n\n"
                                    yielded_anything = True
                                    got_first_chunk = True
                                    
                            # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —á–∞–Ω–∫, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–≤–µ—Ä—à–∞—é—â–µ–µ —Å–æ–±—ã—Ç–∏–µ
                            if got_first_chunk:
                                elapsed = time.time() - start_time
                                print(f"–°—Ç—Ä–∏–º–∏–Ω–≥ –æ—Ç {current_provider} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
                                yield f"event: complete\ndata: {json.dumps({'text': response_text, 'provider': current_provider, 'elapsed': elapsed})}\n\n"
                                return
                                
                        except Exception as e:
                            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–º {current_provider}: {str(e)}")
                    
                    except Exception as provider_error:
                        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ {current_provider}: {str(provider_error)}")
                else:
                    print(f"–ü—Ä–æ–≤–∞–π–¥–µ—Ä {current_provider} –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Å–ø–∏—Å–∫–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö")
                
                # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—Å–Ω–æ–≤–Ω–æ–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä, –ø–æ–ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –≥—Ä—É–ø–ø—ã
                for group_name in ['primary', 'secondary', 'fallback']:
                    print(f"–ü—Ä–æ–±—É–µ–º –≥—Ä—É–ø–ø—É –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤: {group_name}")
                    
                    for backup_provider in provider_groups[group_name]:
                        if backup_provider == current_provider or backup_provider not in providers:
                            continue
                            
                        try:
                            provider = providers[backup_provider]
                            print(f"–ü—Ä–æ–±—É–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä {backup_provider}")
                            
                            yield f"event: update\ndata: {json.dumps({'text': f'–ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ {backup_provider}...', 'provider': backup_provider})}\n\n"
                            
                            try:
                                response_stream = g4f.ChatCompletion.create(
                                    model="gpt-3.5-turbo",
                                    messages=messages,
                                    provider=provider,
                                    stream=True,
                                    timeout=timeout
                                )
                                
                                response_text = ''
                                chunk_count = 0
                                got_any_chunks = False
                                
                                for chunk in response_stream:
                                    chunk_count += 1
                                    if isinstance(chunk, str):
                                        response_text += chunk
                                        print(f"–†–µ–∑–µ—Ä–≤–Ω—ã–π —á–∞–Ω–∫ {chunk_count} –æ—Ç {backup_provider}: {chunk[:30]}...")
                                        yield f"event: chunk\ndata: {json.dumps({'text': chunk, 'provider': backup_provider})}\n\n"
                                        yielded_anything = True
                                        got_any_chunks = True
                                
                                if got_any_chunks:
                                    elapsed = time.time() - start_time
                                    print(f"–°—Ç—Ä–∏–º–∏–Ω–≥ –æ—Ç —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ {backup_provider} –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
                                    yield f"event: complete\ndata: {json.dumps({'text': response_text, 'provider': backup_provider, 'elapsed': elapsed})}\n\n"
                                    return
                                    
                            except Exception as e:
                                print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å —Ä–µ–∑–µ—Ä–≤–Ω—ã–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–º {backup_provider}: {str(e)}")
                                
                        except Exception as provider_error:
                            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ {backup_provider}: {str(provider_error)}")
                
                # –ï—Å–ª–∏ –≤—Å–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É
                print("‚ùå –í—Å–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É")
                elapsed = time.time() - start_time
                yield f"event: error\ndata: {json.dumps({'error': '–í—Å–µ AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.', 'elapsed': elapsed})}\n\n"
            
            except Exception as e:
                print(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–µ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞: {str(e)}")
                traceback.print_exc()
                
                # –í —Å–ª—É—á–∞–µ –æ–±—â–µ–π –æ—à–∏–±–∫–∏, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
                elapsed = time.time() - start_time
                yield f"event: error\ndata: {json.dumps({'error': '–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.', 'elapsed': elapsed})}\n\n"
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ—Ç–æ–∫–æ–≤—ã–π –æ—Ç–≤–µ—Ç
        return Response(stream_generator(), content_type='text/event-stream')
        
    except Exception as e:
        print(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}")
        traceback.print_exc()
        return Response('–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞', status=500)

# –ü—Ä–æ—Å—Ç–æ–π —Ç–µ—Å—Ç–æ–≤—ã–π –º–∞—Ä—à—Ä—É—Ç
@app.route('/test', methods=['GET'])
def test():
    return jsonify({"status": "ok", "message": "Flask-—Å–µ—Ä–≤–µ—Ä —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç"})

# –ú–∞—Ä—à—Ä—É—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
@app.route('/test-provider/<provider_name>', methods=['GET'])
def test_provider(provider_name):
    if provider_name not in providers:
        return jsonify({"status": "error", "message": f"–ü—Ä–æ–≤–∞–π–¥–µ—Ä {provider_name} –Ω–µ –Ω–∞–π–¥–µ–Ω"})
    
    provider = providers[provider_name]
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ç—Ä–µ–±—É–µ—Ç –ª–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä API-–∫–ª—é—á
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        response = g4f.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": "Say just one word: Test"}],
            provider=provider,
            timeout=5  # –ö–æ—Ä–æ—Ç–∫–∏–π —Ç–∞–π–º–∞—É—Ç
        )
        
        return jsonify({
            "status": "ok", 
            "message": f"–ü—Ä–æ–≤–∞–π–¥–µ—Ä {provider_name} –¥–æ—Å—Ç—É–ø–µ–Ω", 
            "requires_api_key": False,
            "response": str(response)[:100]  # –¢–æ–ª—å–∫–æ –Ω–∞—á–∞–ª–æ –æ—Ç–≤–µ—Ç–∞
        })
    except Exception as e:
        error_str = str(e)
        requires_api_key = any(key in error_str.lower() for key in ["api_key", "apikey", "key", "token"])
        
        return jsonify({
            "status": "error",
            "message": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ {provider_name}",
            "error": error_str,
            "requires_api_key": requires_api_key
        })

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞
if __name__ == '__main__':
    print("–ó–∞–ø—É—Å–∫ —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞ –Ω–∞ –ø–æ—Ä—Ç—É 5001...")
    app.run(host='0.0.0.0', port=5001, debug=True, threaded=True)
